{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:01.592799Z","iopub.execute_input":"2022-05-27T15:37:01.593144Z","iopub.status.idle":"2022-05-27T15:37:02.360835Z","shell.execute_reply.started":"2022-05-27T15:37:01.593053Z","shell.execute_reply":"2022-05-27T15:37:02.359801Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/quora-question-pairs/train.csv.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:02.362941Z","iopub.execute_input":"2022-05-27T15:37:02.363622Z","iopub.status.idle":"2022-05-27T15:37:04.709809Z","shell.execute_reply.started":"2022-05-27T15:37:02.363569Z","shell.execute_reply":"2022-05-27T15:37:04.708804Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Dataset Description","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:04.711649Z","iopub.execute_input":"2022-05-27T15:37:04.712126Z","iopub.status.idle":"2022-05-27T15:37:04.716073Z","shell.execute_reply.started":"2022-05-27T15:37:04.712081Z","shell.execute_reply":"2022-05-27T15:37:04.714983Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:04.718687Z","iopub.execute_input":"2022-05-27T15:37:04.718957Z","iopub.status.idle":"2022-05-27T15:37:04.736024Z","shell.execute_reply.started":"2022-05-27T15:37:04.718898Z","shell.execute_reply":"2022-05-27T15:37:04.735099Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:04.737750Z","iopub.execute_input":"2022-05-27T15:37:04.738902Z","iopub.status.idle":"2022-05-27T15:37:04.769115Z","shell.execute_reply.started":"2022-05-27T15:37:04.738838Z","shell.execute_reply":"2022-05-27T15:37:04.767942Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:04.771024Z","iopub.execute_input":"2022-05-27T15:37:04.772276Z","iopub.status.idle":"2022-05-27T15:37:04.806497Z","shell.execute_reply.started":"2022-05-27T15:37:04.772221Z","shell.execute_reply":"2022-05-27T15:37:04.805613Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:04.808467Z","iopub.execute_input":"2022-05-27T15:37:04.809117Z","iopub.status.idle":"2022-05-27T15:37:04.938104Z","shell.execute_reply.started":"2022-05-27T15:37:04.809067Z","shell.execute_reply":"2022-05-27T15:37:04.936951Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()\ndf = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:04.940202Z","iopub.execute_input":"2022-05-27T15:37:04.940892Z","iopub.status.idle":"2022-05-27T15:37:05.245324Z","shell.execute_reply.started":"2022-05-27T15:37:04.940838Z","shell.execute_reply":"2022-05-27T15:37:05.244289Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Liter Dataset\n#df = df.sample(200000)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:05.246845Z","iopub.execute_input":"2022-05-27T15:37:05.247703Z","iopub.status.idle":"2022-05-27T15:37:05.253297Z","shell.execute_reply.started":"2022-05-27T15:37:05.247613Z","shell.execute_reply":"2022-05-27T15:37:05.252467Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"questions_df = df[['question1','question2']]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:05.256045Z","iopub.execute_input":"2022-05-27T15:37:05.257009Z","iopub.status.idle":"2022-05-27T15:37:05.292308Z","shell.execute_reply.started":"2022-05-27T15:37:05.256912Z","shell.execute_reply":"2022-05-27T15:37:05.290685Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install contractions\n!pip install session_info\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom string import punctuation\nimport re\nimport contractions\n\ndef tokenize(text):\n    return word_tokenize(text)\n\ndef remove_stopwords(text):\n    list_of_words = tokenize(text)\n    _stopwords = set(stopwords.words(\"english\"))\n    filtered_list = [word + ' ' for word in list_of_words if word.casefold() not in _stopwords]\n    return (''.join(filtered_list))[: -1] # to remove space at the end of string\n\ndef lemmatize(text):\n    words = tokenize(text)\n    lemmatizer = WordNetLemmatizer()\n    lem_words = [lemmatizer.lemmatize(word, pos='v')+' ' for word in words]\n    return (''.join(lem_words))[: -1] # to remove space at the end of string\n\ndef preprocessing(text):\n    text = re.sub('[0-9]+\\.[0-9]+', \"1\", str(text)) # Remove float numbers\n    constructed_txt = contractions.fix(text) # Remove shortened words such as \"we'd\" and return them to original words\n    lem_txt = lemmatize(constructed_txt) # lemmatize words to get the original ones\n    free_stopwords_txt = remove_stopwords(lem_txt) # remove stopwords\n    text = ''.join([c for c in text if c not in punctuation]).lower()\n    return text\n    #print(text)\n\n#preprocessing(\"youssef she's got 5.6 new dog this ?\")\nquestions_df['question1'].apply(preprocessing)\nquestions_df['question2'].apply(preprocessing)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:37:05.295405Z","iopub.execute_input":"2022-05-27T15:37:05.296255Z","iopub.status.idle":"2022-05-27T15:47:20.786802Z","shell.execute_reply.started":"2022-05-27T15:37:05.296199Z","shell.execute_reply":"2022-05-27T15:47:20.786062Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import session_info\nsession_info.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:47:20.788311Z","iopub.execute_input":"2022-05-27T15:47:20.788749Z","iopub.status.idle":"2022-05-27T15:47:21.075026Z","shell.execute_reply.started":"2022-05-27T15:47:20.788699Z","shell.execute_reply":"2022-05-27T15:47:21.073791Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#print(questions_df['question1'])\n#print(questions_df['question2'])\n# ddf = pd.concat([questions_df['question1'],questions_df['question2']])\n# print(ddf['question1'])\n# print(ddf['question2'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-27T15:47:21.076572Z","iopub.execute_input":"2022-05-27T15:47:21.076898Z","iopub.status.idle":"2022-05-27T15:47:21.082144Z","shell.execute_reply.started":"2022-05-27T15:47:21.076856Z","shell.execute_reply":"2022-05-27T15:47:21.080718Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nimport scipy\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import losses \nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\n\n\ncount_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\nnew_df = pd.concat((questions_df['question1'],questions_df['question2']))\ncv = count_vect.fit_transform(new_df)\ntrainq1_trans = count_vect.transform(questions_df['question1'].values.astype(str))\ntrainq2_trans = count_vect.transform(questions_df['question2'].values.astype(str))\n\nlabels = df['is_duplicate'].values\nX = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\ny = labels\nX_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)\n\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=X.get_shape()[1], activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nprint(X.get_shape())\nprint(X_train.get_shape())\n\nmodel.compile(loss = 'mean_squared_error', optimizer = 'sgd', metrics = [metrics.categorical_accuracy])\nmodel.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n\n_, accuracy = model.evaluate(X_valid, y_valid)\nprint('Accuracy: %.2f' % (accuracy*100))\n\n# xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n# xgb_prediction = xgb_model.predict(X_valid)\n\n# from sklearn.metrics import f1_score, classification_report, accuracy_score\n\n# print('training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n# print('validation score:', f1_score(y_valid, xgb_model.predict(X_valid), average='macro'))\n# print(classification_report(y_valid, xgb_prediction))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:05:53.355077Z","iopub.execute_input":"2022-05-27T16:05:53.355385Z","iopub.status.idle":"2022-05-27T18:17:49.286182Z","shell.execute_reply.started":"2022-05-27T16:05:53.355353Z","shell.execute_reply":"2022-05-27T18:17:49.283477Z"},"trusted":true},"execution_count":15,"outputs":[]}]}
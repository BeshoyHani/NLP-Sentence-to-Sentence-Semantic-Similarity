{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:21.24174Z","iopub.execute_input":"2022-05-30T06:57:21.24291Z","iopub.status.idle":"2022-05-30T06:57:22.215466Z","shell.execute_reply.started":"2022-05-30T06:57:21.242796Z","shell.execute_reply":"2022-05-30T06:57:22.214673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../dataset/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:22.217015Z","iopub.execute_input":"2022-05-30T06:57:22.217362Z","iopub.status.idle":"2022-05-30T06:57:23.977237Z","shell.execute_reply.started":"2022-05-30T06:57:22.217327Z","shell.execute_reply":"2022-05-30T06:57:23.976308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset Description","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:23.978496Z","iopub.execute_input":"2022-05-30T06:57:23.978856Z","iopub.status.idle":"2022-05-30T06:57:23.982154Z","shell.execute_reply.started":"2022-05-30T06:57:23.978806Z","shell.execute_reply":"2022-05-30T06:57:23.981272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:23.984485Z","iopub.execute_input":"2022-05-30T06:57:23.985205Z","iopub.status.idle":"2022-05-30T06:57:23.99791Z","shell.execute_reply.started":"2022-05-30T06:57:23.985145Z","shell.execute_reply":"2022-05-30T06:57:23.996975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:23.999492Z","iopub.execute_input":"2022-05-30T06:57:24.000086Z","iopub.status.idle":"2022-05-30T06:57:24.019658Z","shell.execute_reply.started":"2022-05-30T06:57:24.000048Z","shell.execute_reply":"2022-05-30T06:57:24.0188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:24.020962Z","iopub.execute_input":"2022-05-30T06:57:24.021363Z","iopub.status.idle":"2022-05-30T06:57:24.046572Z","shell.execute_reply.started":"2022-05-30T06:57:24.021325Z","shell.execute_reply":"2022-05-30T06:57:24.045787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:24.047773Z","iopub.execute_input":"2022-05-30T06:57:24.048253Z","iopub.status.idle":"2022-05-30T06:57:24.162236Z","shell.execute_reply.started":"2022-05-30T06:57:24.048218Z","shell.execute_reply":"2022-05-30T06:57:24.161271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()\ndf = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:24.163761Z","iopub.execute_input":"2022-05-30T06:57:24.1643Z","iopub.status.idle":"2022-05-30T06:57:24.380525Z","shell.execute_reply.started":"2022-05-30T06:57:24.164262Z","shell.execute_reply":"2022-05-30T06:57:24.379702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Liter Dataset\n#df = df.sample(40000)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:24.38212Z","iopub.execute_input":"2022-05-30T06:57:24.382509Z","iopub.status.idle":"2022-05-30T06:57:24.38652Z","shell.execute_reply.started":"2022-05-30T06:57:24.382475Z","shell.execute_reply":"2022-05-30T06:57:24.385364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions_df = df[['question1','question2']]","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:24.390257Z","iopub.execute_input":"2022-05-30T06:57:24.390654Z","iopub.status.idle":"2022-05-30T06:57:24.412786Z","shell.execute_reply.started":"2022-05-30T06:57:24.390618Z","shell.execute_reply":"2022-05-30T06:57:24.412127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install contractions\n!pip install session_info\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom string import punctuation\nimport re\nimport contractions\n\ndef tokenize(text):\n    return word_tokenize(text)\n\ndef remove_stopwords(text):\n    list_of_words = tokenize(text)\n    _stopwords = set(stopwords.words(\"english\"))\n    filtered_list = [word + ' ' for word in list_of_words if word.casefold() not in _stopwords]\n    return (''.join(filtered_list))[: -1] # to remove space at the end of string\n\ndef lemmatize(text):\n    words = tokenize(text)\n    lemmatizer = WordNetLemmatizer()\n    lem_words = [lemmatizer.lemmatize(word, pos='v')+' ' for word in words]\n    return (''.join(lem_words))[: -1] # to remove space at the end of string\n\ndef preprocessing(text):\n    text = re.sub('[0-9]+\\.[0-9]+', \"1\", str(text)) # Remove float numbers\n    constructed_txt = contractions.fix(text) # Remove shortened words such as \"we'd\" and return them to original words\n    lem_txt = lemmatize(constructed_txt) # lemmatize words to get the original ones\n    free_stopwords_txt = remove_stopwords(lem_txt) # remove stopwords\n    text = ''.join([c for c in free_stopwords_txt if c not in punctuation]).lower()\n    return text\n    #print(text)\n\n#preprocessing(\"youssef she's got 5.6 new dog this ?\")\nquestions_df['question1'] = questions_df['question1'].apply(preprocessing)\nquestions_df['question2'] = questions_df['question2'].apply(preprocessing)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T06:57:24.414112Z","iopub.execute_input":"2022-05-30T06:57:24.414462Z","iopub.status.idle":"2022-05-30T07:06:23.160324Z","shell.execute_reply.started":"2022-05-30T06:57:24.414429Z","shell.execute_reply":"2022-05-30T07:06:23.158858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import session_info\nsession_info.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T07:06:23.162059Z","iopub.execute_input":"2022-05-30T07:06:23.162693Z","iopub.status.idle":"2022-05-30T07:06:23.401449Z","shell.execute_reply.started":"2022-05-30T07:06:23.162652Z","shell.execute_reply":"2022-05-30T07:06:23.400559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(questions_df['question1'])\n#print(questions_df['question2'])\n# ddf = pd.concat([questions_df['question1'],questions_df['question2']])\n# print(ddf['question1'])\n# print(ddf['question2'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-30T07:06:23.402796Z","iopub.execute_input":"2022-05-30T07:06:23.403175Z","iopub.status.idle":"2022-05-30T07:06:23.407273Z","shell.execute_reply.started":"2022-05-30T07:06:23.40314Z","shell.execute_reply":"2022-05-30T07:06:23.406443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nimport scipy\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import losses \nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\n\n\ncount_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\nnew_df = pd.concat((questions_df['question1'],questions_df['question2']))\ncv = count_vect.fit_transform(new_df)\ntrainq1_trans = count_vect.transform(questions_df['question1'].values.astype(str))\ntrainq2_trans = count_vect.transform(questions_df['question2'].values.astype(str))\n\nlabels = df['is_duplicate'].values\nx = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\ny = labels\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.33, random_state = 42)\n\nkeras_model = Sequential()\nkeras_model.add(Dense(12, input_dim=x.get_shape()[1], activation='relu'))\nkeras_model.add(Dense(8, activation='relu'))\nkeras_model.add(Dense(1, activation='sigmoid'))\n\n# print(x.get_shape())\n# print(x_train.get_shape())\n\nkeras_model.compile(loss = 'mean_squared_error', optimizer = 'sgd', metrics = [metrics.categorical_accuracy])\n\n\n\nkeras_model.fit(x_train, y_train, epochs=50, batch_size=10)\n\ny_predict = keras_model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T07:08:18.37646Z","iopub.execute_input":"2022-05-30T07:08:18.376828Z","iopub.status.idle":"2022-05-30T07:08:41.132106Z","shell.execute_reply.started":"2022-05-30T07:08:18.376796Z","shell.execute_reply":"2022-05-30T07:08:41.131206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report, accuracy_score\nkeras_model.save(\"keras_model.h5\")\n\ny_predict = np.array(y_predict)\ny_predict = y_predict.flatten()\nprint(y_predict)\n\ny_train_predict = (keras_model.predict(x_train) >= 0.5).astype(int)\ny_predict = (keras_model.predict(x_test) >= 0.5).astype(int)\n\nprint('training F1 score:', f1_score(y_train, y_train_predict, average='macro'))\nprint('testing F1 score:', f1_score(y_test, y_predict, average='macro'))\n\nprint(\"\\ntesting Accuracy: \", str(round(accuracy_score(y_test, y_predict)*100, 2)),'%')\n\nprint('\\ntesting report: ')\nprint(classification_report(y_test, y_predict))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T07:06:23.42117Z","iopub.execute_input":"2022-05-30T07:06:23.421565Z","iopub.status.idle":"2022-05-30T07:06:23.428965Z","shell.execute_reply.started":"2022-05-30T07:06:23.421532Z","shell.execute_reply":"2022-05-30T07:06:23.427901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nxgb_model = xgb.XGBClassifier(max_depth=100, n_estimators=90, learning_rate=0.3, colsample_bytree=.7, gamma=0, reg_alpha=3, objective='binary:logistic', silent=1, subsample=0.8).fit(x_train, y_train) \nxgb_prediction = xgb_model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T07:39:51.650054Z","iopub.execute_input":"2022-05-30T07:39:51.650436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report, accuracy_score\nprint('training F1 score:', f1_score(y_train, xgb_model.predict(x_train), average='macro'))\nprint('testing F1 score:', f1_score(y_test, xgb_prediction, average='macro'))\n\nprint(\"\\ntesting Accuracy: \", str(round(accuracy_score(y_test, xgb_prediction)*100, 2)),'%')\n\nprint('\\ntesting report: ')\nprint(classification_report(y_test, xgb_prediction))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}